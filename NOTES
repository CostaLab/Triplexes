--- Notes and ideas on the original triplexator implementation ---

[ TFO detection ]
	* Automaton based filtering to find regions with at most {omega} consecutive errors.
	* =filterRepeats= ignore low complexity regions such as "GA" and "GAA" using SeqAn's function which is based on lazy
      suffix trees. Min-max lengths of such regions are given as parameter. This is done for each Oligo sequence.
    * Input sequence is split into valid (respecting {omega}) parts using the automaton, and each part is subsequently
      searched for motifs that respect all parameters (length, guanine rate, etc.). This is done with quite a greedy /
      brute-force procedure using some sort of window-shifting along the string. [?]


[ TFO-TTS detection ]
    (mapTriplexes)
    * first it retrieves the TFOs and uses the same findRepeats SeqAn function to remove low complexity regions.
    * maybe detect and handle duplicates, if option is set

    (_findTriplex)
    * an index (suffix array) is created for the set of valid TFOs.
    * A pattern is created from this index, i.e., the set of TFO motifs.

    (startTriplexSearchSerial / Parallel [Gardener / BruteForce])
    * Serial / parallel search, with or without pattern depending on whether QGRAM FILTERING is set
    * iterate over each duplex and remove low complexity regions (repeats)

    (_detectTriplex)
    * Prefilter for putative TTSs, i.e., for each sequence in the duplex file apply filtering to get only substrings
      (possible TTS) that respect the parameters: `processDuplex`
    
!!! (_detectTriplexBruteForce)
    * for each duplex string, previously optimized, we iterate through the TFO set; there's a char-by-char match / check



Summary:_______________________________________________________________________________________________________________
    
    Key observations: 
        a)  if the minimum triplex length is 10 and max allowed error is 1, there must be at least two 4-grams that match
            in `d` and `s`. 

    ========================================

    First it retrieves the TFOs and uses the same findRepeats SeqAn function to remove low complexity regions.
    Duplicates may be detected and handled, if option is set. An index (IndexQGram) based on an array of sorted q-grams
    is then created from the set of TFOs. More exactly, this index is a complex data structure containing a sorted suffix 
    array, some tables (directories) mapping the hash values of q-grams to indices in the suffix array, etc.
    
        [IndexQGram]: The fibres (see Index and Fibre) of this index are a suffix array sorted by the first q characters
                     (see QGramSA) and a q-gram directory (see QGramDir). The size of the q-gram directory is |Î£|^q. On 
                     a 32bit system the q-gram length is limited to 3 for char alphabets or 13-14 for Dna alphabets. 
        [QGramSA]   :  The suffix array. Remarks: Contains all occurrences of q-grams, s.t. the occurrences of a single 
                       q-gram are stored in a contiguous block (q-gram bucket). q-grams exceeding the end of the text 
                       are ignored. The beginning of each bucket can be determined by the q-gram directory (QGramDir).
                       It corresponds to a suffix array which is sorted by the first q-gram.
        Functions on the index:
            {countOccurrences(index, shape)}:   Returns the number of occurrences of a q-gram in the index text
            {getOccurrences(index, shape)}  :   Returns an occurrence / OR multiple a q-gram in the index text.

    Next, the file containing the double stranded sequence D is opened and each sequence in this file is processed
    independently / in parallel. Each D is then matched against all entries in the TFO index as follows:
        1)  remove low complexity regions (repeats), similarly to TFOs
        2)  D is processed (processDuplex), i.e., it's broken up into putative TTS subsequences. This way for each D we
            get a set of substrings of D (d_1, d_2, ...) which are actually used in the pattern matching against TFOs.
            ---------------------------------------
            TFOs = PATTERN, NEEDLE (set of strings)
            d_i  = HAYSTACK
            ---------------------------------------
        3*) Collect seeds: get maximal 'seeds' of each TFO in the needle that match anywhere in the haystack (d_i),
            i.e., maximal substrings of each TFO that match d_i somewhere and have a minimum length. This is EXACT
            MATCHING. 
            A "Finder" object is created from the haystack and the pattern, and by recursively calling the SeqAn "find"
            function all common q-gram substrings (q is defined at the beginning) are returned and analyzed. This "find"
            function is based on ..... ??????? TBD
            q-gram matching is based on hash functions / values.

        4)  A scoring schema is calculated and then the seeds / q-grams are extended using the scoring schema and X-Drop
            algorithm.


     =======================================
     Calculating q-gram size
            Size of qgram : (qgram threshold - 1 - minLength) / (- #errors - 1)
            
